name: Working Deployment

on:
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  DOCKER_IMAGE: azexkush/car-lot-manager

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: us-east-1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Terraform Init and Apply
        working-directory: ./terraform
        run: |
          terraform init
          terraform destroy -auto-approve || true
          terraform apply -auto-approve

      - name: Get Infrastructure Details
        id: infra
        working-directory: ./terraform
        run: |
          ALB_DNS=$(terraform output -raw alb_dns_name)
          INSTANCE_IPS=$(terraform output -json instance_ips)
          MASTER_IP=$(echo $INSTANCE_IPS | jq -r '.[0]')
          WORKER1_IP=$(echo $INSTANCE_IPS | jq -r '.[1]')
          WORKER2_IP=$(echo $INSTANCE_IPS | jq -r '.[2]')
          MASTER_PRIVATE_IP=$(terraform output -raw master_private_ip)
          
          echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT
          echo "master_ip=$MASTER_IP" >> $GITHUB_OUTPUT
          echo "worker1_ip=$WORKER1_IP" >> $GITHUB_OUTPUT
          echo "worker2_ip=$WORKER2_IP" >> $GITHUB_OUTPUT
          echo "master_private_ip=$MASTER_PRIVATE_IP" >> $GITHUB_OUTPUT
          
          terraform output -raw ssh_private_key > /tmp/ssh_key.pem
          chmod 400 /tmp/ssh_key.pem

      - name: Wait for Instances
        run: sleep 120

      - name: Install Ansible and Run Playbook
        run: |
          sudo apt-get update && sudo apt-get install -y ansible
          
          cat > inventory.ini << EOF
          [master]
          ${{ steps.infra.outputs.master_ip }} ansible_user=ubuntu ansible_ssh_private_key_file=/tmp/ssh_key.pem ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          
          [worker]
          ${{ steps.infra.outputs.worker1_ip }} ansible_user=ubuntu ansible_ssh_private_key_file=/tmp/ssh_key.pem ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          ${{ steps.infra.outputs.worker2_ip }} ansible_user=ubuntu ansible_ssh_private_key_file=/tmp/ssh_key.pem ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          EOF
          
          ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook -i inventory.ini ansible/simple-playbook.yml

      - name: Deploy Application
        run: |
          # Wait for cluster to be ready
          sleep 60
          
          # Create simple deployment
          cat > app-deployment.yaml << 'EOF'
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: car-lot-app
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: car-lot-app
            template:
              metadata:
                labels:
                  app: car-lot-app
              spec:
                containers:
                - name: car-lot
                  image: azexkush/car-lot-manager:latest
                  ports:
                  - containerPort: 5000
                  env:
                  - name: DATA_FILE
                    value: "/tmp/inventory.json"
                  readinessProbe:
                    httpGet:
                      path: /health
                      port: 5000
                    initialDelaySeconds: 10
                    periodSeconds: 5
                  livenessProbe:
                    httpGet:
                      path: /health
                      port: 5000
                    initialDelaySeconds: 30
                    periodSeconds: 10
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: car-lot-service
          spec:
            type: NodePort
            ports:
            - port: 80
              targetPort: 5000
              nodePort: 30080
            selector:
              app: car-lot-app
          EOF
          
          # Deploy to cluster
          scp -i /tmp/ssh_key.pem -o StrictHostKeyChecking=no app-deployment.yaml ubuntu@${{ steps.infra.outputs.master_ip }}:/tmp/
          
          ssh -i /tmp/ssh_key.pem -o StrictHostKeyChecking=no ubuntu@${{ steps.infra.outputs.master_ip }} "
            kubectl apply -f /tmp/app-deployment.yaml
            kubectl rollout status deployment/car-lot-app --timeout=300s
            kubectl get pods -o wide
            kubectl get svc
          "

      - name: Test and Verify
        run: |
          echo "Testing NodePort..."
          ssh -i /tmp/ssh_key.pem -o StrictHostKeyChecking=no ubuntu@${{ steps.infra.outputs.master_ip }} "
            curl -s http://localhost:30080/health || echo 'NodePort failed'
            curl -s http://localhost:30080/ | head -20 || echo 'Main page failed'
          "
          
          echo "Waiting for Load Balancer..."
          sleep 120
          
          echo "Testing Load Balancer..."
          for i in {1..10}; do
            echo "Attempt $i/10..."
            if curl -s --connect-timeout 10 "http://${{ steps.infra.outputs.alb_dns }}/health" | grep -q "healthy"; then
              echo "âœ… SUCCESS! Application is working!"
              break
            fi
            sleep 30
          done

      - name: Final Result
        run: |
          echo ""
          echo "=========================================="
          echo "ðŸŽ‰ DEPLOYMENT COMPLETED!"
          echo "=========================================="
          echo ""
          echo "ðŸŒ Access your Car Lot Manager at:"
          echo ""
          echo "    http://${{ steps.infra.outputs.alb_dns }}"
          echo ""
          echo "=========================================="